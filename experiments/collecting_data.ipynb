{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Get all files from all complete_results folders\n",
    "def get_file_list(dirName):\n",
    "    # create a list of file and sub directories\n",
    "    # names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + get_file_list(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "\n",
    "    return allFiles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\horizontal_normal\\1_2020-11-10_13-01-52.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\1_2020-11-11_14-44-31.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\1_2020-11-13_13-59-46.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\2_2020-11-11_14-57-07.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\2_2020-11-13_14-03-46.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\3_2020-11-12_15-21-13.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\3_2020-11-13_14-10-38.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\4_2020-11-12_16-05-57.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\4_2020-11-13_14-22-59.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\5_2020-11-13_11-06-26.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\5_2020-11-13_14-25-52.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\6_2020-11-13_14-32-06.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\7_2020-11-17_17-17-43.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_extra_assembly_comp\\1_2020-11-11_14-32-44.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\1_2020-11-11_15-05-54.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\2_2020-11-11_15-15-14.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\3_2020-11-11_15-16-59.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\4_2020-11-13_14-36-16.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\5_2020-11-17_15-49-16.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\1_2020-11-10_12-27-27.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\2_2020-11-11_11-45-20.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\3_2020-11-11_15-58-16.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\4_2020-11-13_15-28-47.csv\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\5_2020-11-17_16-33-58.csv\n"
     ]
    }
   ],
   "source": [
    "# data_path = 'E:/source/repos/robot_dataset'\n",
    "data_path = 'C:/Users/au614889/PycharmProjects/robot_dataset'\n",
    "dirName = data_path + '/complete_results'\n",
    "\n",
    "total_samples = 1767\n",
    "normal_samples = 1245\n",
    "extra_assembly_samples = 181\n",
    "damaged_screw_samples = 155\n",
    "missing_screw_samples = 185\n",
    "damaged_thread_hole_samples = 1\n",
    "loosen_samples = 5000\n",
    "\n",
    "# Get the list of all files in directory tree at given path\n",
    "files_list = get_file_list(dirName)\n",
    "files_list = [x for x in files_list if '.h5' not in x]\n",
    "\n",
    "# Print the files\n",
    "for elem in files_list:\n",
    "    print(elem)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def label_samples(data, mode):\n",
    "    # Change the unscrewing samples(odd numbers) to their own label or anomaly\n",
    "    if mode == 'partial':\n",
    "        data.loc[data['sample_nr'] % 2 != 0, ['label']]  = 5\n",
    "    elif mode == 'relabel_full':\n",
    "        data['label_shifted'] = data['label'].shift(-1)\n",
    "        data['label'] = np.where(data['label'] < data['label_shifted'],\n",
    "                                          data['label_shifted'],\n",
    "                                          data['label'])\n",
    "        complete_data = data.drop(['label_shifted'], axis=1)\n",
    "        complete_data.fillna(0)\n",
    "    elif mode == 'full':\n",
    "        data['sample_shifted'] = data['sample_nr'] - 1\n",
    "        data['sample_nr'] = np.where(data['sample_nr'] % 2 == 0,\n",
    "                                          data['sample_shifted'],\n",
    "                                          data['sample_nr'])\n",
    "        data = data.drop(['sample_shifted'], axis=1)\n",
    "\n",
    "        # Renumber samples\n",
    "        data['sample_nr'] = (data['sample_nr'] !=\n",
    "                                      data['sample_nr'].shift(1)).astype(int).cumsum()\n",
    "    data.sort_index()\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def smooth_samples(data):\n",
    "    # Smooth all the labels in a sample\n",
    "    data['label'] = data.groupby(['sample_nr'])['label'].transform(\n",
    "        lambda x: int(np.round(x.mean(), decimals=0))\n",
    "    )\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def amount_to_take(target, taken, n_samples):\n",
    "    if target - taken < 0:\n",
    "        return 0\n",
    "    elif target - taken <= n_samples:\n",
    "        return target - taken\n",
    "    else:\n",
    "        return n_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def change_data_types(data):\n",
    "    # Change dtypes to smaller\n",
    "    for column in list(data):\n",
    "        if data[column].dtype == 'int64' or data[column].dtype == 'int32':\n",
    "            data[column] = pd.to_numeric(data[column], errors='coerce', downcast='integer')\n",
    "        if data[column].dtype == 'float64':\n",
    "            data[column] = pd.to_numeric(data[column], errors='coerce', downcast='float')\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def load_data(normal_percentage=1, assembly_percentage=1, damaged_percentage=1, missing_percentage=1, hole_percentage=1,\n",
    "              label_type='partial', data_type='continous', files_list=None, drop_columns=False):\n",
    "    dataframe_list = []\n",
    "    # Number of taken samples\n",
    "    taken_0 = 0\n",
    "    taken_1 = 0\n",
    "    taken_2 = 0\n",
    "    taken_3 = 0\n",
    "    taken_4 = 0\n",
    "    taken_5 = 0\n",
    "\n",
    "    # Target number of samples\n",
    "    target_0 = int(normal_percentage * normal_samples)\n",
    "    target_1 = int(assembly_percentage * extra_assembly_samples)\n",
    "    target_2 = int(damaged_percentage * damaged_screw_samples)\n",
    "    target_3 = int(missing_percentage * missing_screw_samples)\n",
    "    target_4 = int(hole_percentage * damaged_thread_hole_samples)\n",
    "    target_5 = int(1 * loosen_samples)\n",
    "\n",
    "    for file in files_list:\n",
    "        print(file)\n",
    "        # Reading the file content to a DataFrame\n",
    "        dfn = pd.read_csv(file, sep=',')\n",
    "\n",
    "        # Number the samples\n",
    "        dfn = label_samples(data=dfn, mode=label_type)\n",
    "        dfn = smooth_samples(data=dfn)\n",
    "        dfn = dfn.set_index(['sample_nr'])\n",
    "\n",
    "        # Count the sample types\n",
    "        count_df = dfn.groupby(['sample_nr'])['label'].median()\n",
    "        unique, counts = np.unique(count_df, return_counts=True)\n",
    "        labels_count_dict = {A: B for A, B in zip(unique, counts)}\n",
    "        print(f'Loaded labels: {labels_count_dict}')\n",
    "        dataframe_list.append(dfn)\n",
    "\n",
    "        # if drop_columns:\n",
    "        #     dfn = dfn.drop(columns=['output_int_register_25',\n",
    "        #                             'output_int_register_26',\n",
    "        #                             'output_bit_register_64',\n",
    "        #                             'output_bit_register_65',\n",
    "        #                             'output_bit_register_66',\n",
    "        #                             'output_bit_register_67'], axis=1)\n",
    "        #\n",
    "        # # Take only the amount of samples that's needed to fill the requirement\n",
    "        # sampled_list = []\n",
    "        # for label in unique:\n",
    "        #     subindex = list(np.unique(dfn.loc[dfn['label'] == label].index))\n",
    "        #     to_take = amount_to_take(eval('target_' + str(int(label))), eval('taken_' + str(int(label))), labels_count_dict.get(label))\n",
    "        #\n",
    "        #     sample_ids = np.random.choice(subindex, to_take, replace=False)\n",
    "        #     sampled_df = dfn[dfn.index.isin(sample_ids)]\n",
    "        #     sampled_list.append(sampled_df)\n",
    "        #\n",
    "        #     # Update the taken samples\n",
    "        #     if label == 0:\n",
    "        #         taken_0 += to_take\n",
    "        #     elif label == 1:\n",
    "        #         taken_1 += to_take\n",
    "        #     elif label == 2:\n",
    "        #         taken_2 += to_take\n",
    "        #     elif label == 3:\n",
    "        #         taken_3 += to_take\n",
    "        #     elif label == 4:\n",
    "        #         taken_4 += to_take\n",
    "        #     elif label == 5:\n",
    "        #         taken_5 += to_take\n",
    "        # print([taken_5, taken_0, taken_1, taken_2, taken_3, taken_4])\n",
    "        # print('\\n')\n",
    "        #\n",
    "        # taken_data = change_data_types(pd.concat(sampled_list, ignore_index=False).sort_values(['sample_nr', 'timestamp']))\n",
    "        # dataframe_list.append(taken_data)\n",
    "        #\n",
    "        # if taken_0 >= target_0 and taken_1 >= target_1 and taken_2 >= target_2 and taken_3 >= target_3 and taken_4 >= target_4:\n",
    "        #     print(f'Finished at {file}')\n",
    "        #     break\n",
    "\n",
    "        # # Save the loaded file to hdf5\n",
    "        # file_path = Path(file)\n",
    "        # hdf_path = file_path.parents[0] / (file_path.parts[-1][:-4] + '.h5')\n",
    "        # taken_data.to_hdf(path_or_buf=hdf_path,\n",
    "        #                   key=file_path.parts[-1][:-4])\n",
    "\n",
    "    # Concat those dataframes\n",
    "    complete_data = pd.concat(dataframe_list, ignore_index=False)\n",
    "    complete_data = complete_data.reset_index()\n",
    "    # if drop_columns:\n",
    "    #     complete_data = complete_data.drop(columns=['timestamp'], axis=1)\n",
    "    # Renumber samples\n",
    "    complete_data['sample_nr'] = (complete_data['sample_nr'] != complete_data['sample_nr'].shift(1)).astype(int).cumsum()\n",
    "    del dataframe_list\n",
    "    gc.collect()\n",
    "\n",
    "    return complete_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\horizontal_normal\\1_2020-11-10_13-01-52.csv\n",
      "{0: 65, 5: 66}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\1_2020-11-11_14-44-31.csv\n",
      "{0: 53, 1: 9, 2: 7, 3: 4, 5: 73}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\1_2020-11-13_13-59-46.csv\n",
      "{0: 71, 2: 18, 5: 89}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\2_2020-11-11_14-57-07.csv\n",
      "{0: 51, 1: 23, 2: 11, 3: 6, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\2_2020-11-13_14-03-46.csv\n",
      "{0: 110, 1: 5, 2: 30, 4: 2, 5: 147}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\3_2020-11-12_15-21-13.csv\n",
      "{0: 47, 1: 15, 2: 23, 3: 6, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\3_2020-11-13_14-10-38.csv\n",
      "{0: 61, 1: 20, 2: 5, 3: 2, 5: 89}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\4_2020-11-12_16-05-57.csv\n",
      "{0: 65, 1: 15, 2: 3, 3: 6, 5: 90}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\4_2020-11-13_14-22-59.csv\n",
      "{0: 46, 1: 15, 2: 23, 3: 6, 5: 90}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\5_2020-11-13_11-06-26.csv\n",
      "{0: 67, 1: 3, 2: 19, 4: 1, 5: 90}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\5_2020-11-13_14-25-52.csv\n",
      "{0: 51, 1: 23, 2: 11, 3: 6, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\6_2020-11-13_14-32-06.csv\n",
      "{0: 37, 1: 8, 2: 24, 3: 2, 5: 72}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_damaged_screw_thread\\7_2020-11-17_17-17-43.csv\n",
      "{0: 82, 2: 9, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_extra_assembly_comp\\1_2020-11-11_14-32-44.csv\n",
      "{0: 138, 1: 46, 5: 184}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\1_2020-11-11_15-05-54.csv\n",
      "{0: 45, 3: 46, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\2_2020-11-11_15-15-14.csv\n",
      "{0: 37, 1: 9, 3: 45, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\3_2020-11-11_15-16-59.csv\n",
      "{0: 33, 1: 12, 3: 46, 5: 91}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\4_2020-11-13_14-36-16.csv\n",
      "{0: 71, 3: 19, 5: 90}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_missing_screw\\5_2020-11-17_15-49-16.csv\n",
      "{0: 60, 1: 8, 3: 22, 5: 90}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\1_2020-11-10_12-27-27.csv\n",
      "{0: 79, 5: 79}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\2_2020-11-11_11-45-20.csv\n",
      "{0: 85, 5: 85}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\3_2020-11-11_15-58-16.csv\n",
      "{0: 32, 1: 10, 5: 42}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\4_2020-11-13_15-28-47.csv\n",
      "{0: 18, 5: 18}\n",
      "C:/Users/au614889/PycharmProjects/robot_dataset/complete_results\\spiral_normal\\5_2020-11-17_16-33-58.csv\n",
      "{0: 16, 3: 2, 5: 18}\n"
     ]
    }
   ],
   "source": [
    "# Read all files into pandas\n",
    "complete_data = load_data(normal_percentage=1,\n",
    "                          assembly_percentage=1,\n",
    "                          damaged_percentage=1,\n",
    "                          missing_percentage=1,\n",
    "                          hole_percentage=1,\n",
    "                          label_type='partial',\n",
    "                          files_list=files_list[:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4094 samples in total.\n",
      "The types and counts of different labels as percentage of total data: \n",
      " {0: 34.68, 1: 5.4, 2: 4.47, 3: 5.32, 4: 0.07, 5: 50.05}\n"
     ]
    }
   ],
   "source": [
    "# Data statistics\n",
    "# Number of total samples\n",
    "print('There are {n_samples} samples in total.'.format(n_samples=max(list(complete_data['sample_nr']))))\n",
    "# print('There are {n_samples} samples in total.'.format(n_samples=max(list(complete_data.index))/2))\n",
    "\n",
    "# Count the different types of labels\n",
    "grouped_df = complete_data.groupby(['label', 'sample_nr'])['output_double_register_25'].count()\n",
    "\n",
    "unique = list(grouped_df.index.get_level_values(0).unique())\n",
    "count = []\n",
    "for id in unique:\n",
    "    count.append(np.round(len(grouped_df.loc[id, :]) / max(complete_data['sample_nr']) * 100, decimals=2))\n",
    "\n",
    "# count_dict = {A: B for A, B in zip(unique, np.round((count / max(complete_data['sample_nr'])) * 100, decimals=2))}\n",
    "count_dict = {unique[i]: count[i] for i in range(len(unique))}\n",
    "\n",
    "print('The types and counts of different labels as percentage of total data: \\n {count_dict}'.format(count_dict=count_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Save the data\n",
    "complete_data.to_hdf('C:/Users/au614889/PycharmProjects/robot_dataset/created_dataset/robot_data.h5',\n",
    "                     key='complete_data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plot_data = complete_data[:]\n",
    "\n",
    "plt.plot(plot_data['label'])\n",
    "plt.plot(plot_data['sample_nr'] / 100)\n",
    "plt.plot(plot_data['output_double_register_25'])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# experiment_data = complete_data[:]\n",
    "#\n",
    "# experiment_data['event'] = experiment_data.index\n",
    "# experiment_data = experiment_data.set_index(['sample_nr', 'event'])\n",
    "# experiment_data = experiment_data.reset_index('event', drop=True)\n",
    "# experiment_data = experiment_data.set_index(experiment_data.groupby(level=0).cumcount().rename('event'), append=True)\n",
    "# # experiment_data = experiment_data.drop(columns=['event'], axis=1)\n",
    "# max_rows = experiment_data.index.get_level_values(1).max()\n",
    "#\n",
    "# print(experiment_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm as tqdm\n",
    "#\n",
    "# def pad_df(df):\n",
    "#     # 1. compute the sizes of each sample_nr\n",
    "#     sr_sizes = df.groupby(df.index.get_level_values(0)).size()\n",
    "#     # compute max size and #sample_nr\n",
    "#     max_size = sr_sizes.max()\n",
    "#     n_sample_nrs = len(sr_sizes)\n",
    "#\n",
    "#     # 2. preallocate the output array and fill\n",
    "#     arr = np.zeros((max_size * n_sample_nrs, 126))\n",
    "#     idx_lv0 = df.index.get_level_values(0)  # get sample_nr\n",
    "#     for i in tqdm(range(n_sample_nrs)):\n",
    "#         row = i*max_size\n",
    "#         arr[row:row + sr_sizes.iloc[i], :] =\\\n",
    "#             df[idx_lv0 == sr_sizes.index[i]].values\n",
    "#\n",
    "#     # 3. convert to dataframe\n",
    "#     df_ans = pd.DataFrame(\n",
    "#         data=arr,\n",
    "#         index=pd.MultiIndex.from_product([sr_sizes.index, range(max_size)]),\n",
    "#         columns=df.columns\n",
    "#     ).rename_axis(df.index.names, axis=0)\n",
    "#\n",
    "#     return df_ans\n",
    "#\n",
    "# padded_df = pad_df(experiment_data)\n",
    "# print(padded_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8dac9c70",
   "language": "python",
   "display_name": "PyCharm (anomaly_detection)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}